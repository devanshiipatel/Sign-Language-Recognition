{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "gSK6IXHOv6xN"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from gtts import gTTS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "2Z4tdiQkv96E"
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model(r\"C:\\Users\\devan_s1ts7c0\\OneDrive\\Desktop\\Sign Language Recognition\\classifier.h5\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Pg_KLSokv98t"
   },
   "outputs": [],
   "source": [
    "labels_dict = {0:'0', \n",
    "                 1:'A', \n",
    "                 2:'B', \n",
    "                 3:'C', \n",
    "                 4:'D', \n",
    "                 5:'E',\n",
    "                 6:'F',\n",
    "                 7:'G',\n",
    "                 8:'H',\n",
    "                 9:'I',\n",
    "                 10:'J',\n",
    "                 11:'K',\n",
    "                 12:'L',\n",
    "                 13:'M',\n",
    "                 14:'N',\n",
    "                 15:'O',\n",
    "                 16:'P',\n",
    "                 17:\"Q\",\n",
    "                 18:'R',\n",
    "                 19:'S',\n",
    "                 20:'T', \n",
    "                 21:'U', \n",
    "                 22:'V',\n",
    "                 23:'W',\n",
    "                 24:'X',\n",
    "                 25:'Y',\n",
    "                 26:'Z'}\n",
    "\n",
    "color_dict = (0,255,0)\n",
    "x = 0\n",
    "y = 0\n",
    "w = 64\n",
    "h = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "d7i5EK0Tv9-p",
    "outputId": "8a307be7-0b0d-4e2f-e815-1c618a8e0ed6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ATAQQA U HTYMSATAAT\n"
     ]
    }
   ],
   "source": [
    "img_size = 128\n",
    "minValue = 70\n",
    "source=cv2.VideoCapture(0)\n",
    "count = 0\n",
    "string = \" \"\n",
    "prev = \" \"\n",
    "prev_val = 0\n",
    "\n",
    "while(True):\n",
    "    \n",
    "    ret, img = source.read()  # Read video\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n",
    "    #cv2.rectangle(img,(x,y),(x+w,y+h),color_dict,2)\n",
    "    cv2.rectangle(img, (24,24), (250 , 250), color_dict, 2)  # Draw rectangle on screen\n",
    "    crop_img = gray[24:250, 24:250]\n",
    "    count = count + 1\n",
    "    if(count % 100 == 0):  # Display 1,2 \n",
    "        prev_val = count\n",
    "    cv2.putText(img, str(prev_val//100), (300, 150), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255,255,255), 2) \n",
    "    blur = cv2.GaussianBlur(crop_img,(5,5), 2)  # Smoothen the image (ht, wd, std dev)\n",
    "    th3 = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)  # Separate foreground image from background\n",
    "    ret, res = cv2.threshold(th3, minValue, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "    resized = cv2.resize(res, (img_size,img_size))\n",
    "    normalized = resized/255.0\n",
    "    reshaped = np.reshape(normalized, (1,img_size,img_size,1))\n",
    "    result = model.predict(reshaped)  # Prediction on live video\n",
    "    #print(result)\n",
    "    label = np.argmax(result, axis=1)[0]  # Label of prediction\n",
    "    if(count == 300):\n",
    "        count = 99\n",
    "        prev = labels_dict[label] \n",
    "        if(label == 0):\n",
    "            string = string + \" \"\n",
    "        else:\n",
    "            string = string + prev\n",
    "    \n",
    "    cv2.putText(img, prev, (24, 14), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2) \n",
    "    cv2.putText(img, string, (275, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (200,200,200), 2)\n",
    "    cv2.imshow(\"Gray\", res)    \n",
    "    cv2.imshow('LIVE', img)\n",
    "    key = cv2.waitKey(1)\n",
    "    \n",
    " \n",
    "    if(key == 27):#press Esc. to exit\n",
    "        break\n",
    "        \n",
    "print(string)        \n",
    "cv2.destroyAllWindows()\n",
    "source.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2zYJoP-fv-Ed"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
